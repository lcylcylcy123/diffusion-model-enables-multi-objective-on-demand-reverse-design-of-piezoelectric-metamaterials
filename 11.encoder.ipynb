{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5bcadc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/HOME/scz0ruj/.conda/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class Embed(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.embed = torch.nn.Embedding(30001, 768)\n",
    "        self.pos_embed = torch.nn.Embedding(4, 768)\n",
    "\n",
    "        self.register_buffer('pos_ids', torch.arange(4).unsqueeze(dim=0))\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        #input_ids -> [b, 77]\n",
    "    \n",
    "        #[b, 77] -> [b, 77, 768]\n",
    "        embed = self.embed(input_ids)\n",
    "\n",
    "        #[1, 77] -> [1, 77, 768]\n",
    "        pos_embed = self.pos_embed(self.pos_ids)\n",
    "\n",
    "        #[b, 77, 768]\n",
    "        return embed + pos_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf9984a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 768])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Atten(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.q = torch.nn.Linear(768, 768)\n",
    "        self.k = torch.nn.Linear(768, 768)\n",
    "        self.v = torch.nn.Linear(768, 768)\n",
    "        self.out = torch.nn.Linear(768, 768)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x -> [b, 77, 768]\n",
    "\n",
    "        b = x.shape[0]\n",
    "\n",
    "        #维度不变\n",
    "        #[b, 77, 768]\n",
    "        q = self.q(x) * 0.125\n",
    "        k = self.k(x)\n",
    "        v = self.v(x)\n",
    "\n",
    "        #拆分注意力头\n",
    "        #[b, 77, 768] -> [b, 77, 12, 64] -> [b, 12, 77, 64] -> [b*12, 77, 64]\n",
    "        q = q.reshape(b, 4, 12, 64).transpose(1, 2).reshape(b * 12, 4, 64)\n",
    "        k = k.reshape(b, 4, 12, 64).transpose(1, 2).reshape(b * 12, 4, 64)\n",
    "        v = v.reshape(b, 4, 12, 64).transpose(1, 2).reshape(b * 12, 4, 64)\n",
    "\n",
    "        #计算qk乘积\n",
    "        #[b*12, 77, 64] * [b*12, 64, 77] -> [b*12, 77, 77]\n",
    "        attn = torch.bmm(q, k.transpose(1, 2))\n",
    "\n",
    "        #[b*12, 77, 77] -> [b, 12, 77, 77]\n",
    "        attn = attn.reshape(b, 12, 4, 4)\n",
    "\n",
    "        #覆盖mask\n",
    "        def get_mask(b):\n",
    "            mask = torch.empty(b, 4, 4)\n",
    "\n",
    "            #上三角的部分置为负无穷\n",
    "            mask.fill_(-float('inf'))\n",
    "\n",
    "            #对角线和以下的位置为0\n",
    "            mask.triu_(1)\n",
    "\n",
    "            return mask.unsqueeze(1)\n",
    "\n",
    "        #[b, 12, 77, 77] + [b, 1, 77, 77] -> [b, 12, 77, 77]\n",
    "        attn = attn + get_mask(attn.shape[0]).to(attn.device)\n",
    "\n",
    "        #[b, 12, 77, 77] -> [b*12, 77, 77]\n",
    "        attn = attn.reshape(b * 12, 4, 4)\n",
    "\n",
    "        #计算softmax,被mask的部分值为0\n",
    "        attn = attn.softmax(dim=-1)\n",
    "\n",
    "        #计算和v的乘积\n",
    "        #[b*12, 77, 77] * [b*12, 77, 64] -> [b*12, 77, 64]\n",
    "        attn = torch.bmm(attn, v)\n",
    "\n",
    "        #[b*12, 77, 64] -> [b, 12, 77, 64] -> [b, 77, 12, 64] -> [b, 77, 768]\n",
    "        attn = attn.reshape(b, 12, 4, 64).transpose(1, 2).reshape(b, 4, 768)\n",
    "\n",
    "        #线性输出,维度不变\n",
    "        #[b, 77, 768]\n",
    "        return self.out(attn)\n",
    "\n",
    "\n",
    "Atten()(torch.randn(2, 4, 768)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb319a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ClipEncoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.s1 = torch.nn.Sequential(\n",
    "            torch.nn.LayerNorm(768),\n",
    "            Atten(),\n",
    "        )\n",
    "\n",
    "        self.s2 = torch.nn.Sequential(\n",
    "            torch.nn.LayerNorm(768),\n",
    "            torch.nn.Linear(768, 768),\n",
    "        )\n",
    "\n",
    "        self.s3 = torch.nn.Linear(768, 768)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x -> [2, 77, 768]\n",
    "\n",
    "        #维度不变\n",
    "        #[2, 77, 768]\n",
    "        x = x + self.s1(x)\n",
    "\n",
    "        #[2, 77, 768]\n",
    "        res = x\n",
    "\n",
    "        #[2, 77, 768] -> [2, 77, 3072]\n",
    "        x = self.s2(x)\n",
    "\n",
    "        #维度不变\n",
    "        #[2, 77, 3072]\n",
    "        x = x * (x * 1.702).sigmoid()\n",
    "\n",
    "        #[2, 77, 3072] -> [2, 77, 768]\n",
    "        return res + self.s3(x)\n",
    "\n",
    "\n",
    "ClipEncoder()(torch.randn(2, 4, 768)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "625242f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#经过优化之后的代码量少得吓人...\n",
    "encoder = torch.nn.Sequential(\n",
    "    Embed(),\n",
    "    ClipEncoder(),\n",
    "    ClipEncoder(),\n",
    "    ClipEncoder(),\n",
    "    ClipEncoder(),\n",
    "    ClipEncoder(),\n",
    "    ClipEncoder(),\n",
    "    torch.nn.LayerNorm(768),\n",
    ")\n",
    "\n",
    "encoder(torch.ones(2, 4).long()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2f0de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Embed(\n",
       "    (embed): Embedding(30001, 768)\n",
       "    (pos_embed): Embedding(4, 768)\n",
       "  )\n",
       "  (1): ClipEncoder(\n",
       "    (s1): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Atten(\n",
       "        (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (s2): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (s3): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (2): ClipEncoder(\n",
       "    (s1): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Atten(\n",
       "        (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (s2): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (s3): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (3): ClipEncoder(\n",
       "    (s1): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Atten(\n",
       "        (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (s2): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (s3): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (4): ClipEncoder(\n",
       "    (s1): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Atten(\n",
       "        (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (s2): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (s3): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (5): ClipEncoder(\n",
       "    (s1): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Atten(\n",
       "        (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (s2): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (s3): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (6): ClipEncoder(\n",
       "    (s1): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Atten(\n",
       "        (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (s2): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (s3): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (7): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型权重，并调整为单GPU或CPU格式\n",
    "def load_model(model, model_path):\n",
    "    # 加载保存的状态字典\n",
    "    state_dict = torch.load(model_path)\n",
    "\n",
    "\n",
    "    # 加载调整后的状态字典\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "# 加载模型并进行推断\n",
    "model_path = \"/data/run01/scz0ruj/model/new_encoder_model_parameters18800last.pth\"\n",
    "load_model(encoder, model_path)\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50062c09",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m text \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(text, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# 确保数据类型一致\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 定义条件均值和标准差\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m condition_mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m3.84952491e+02\u001b[39m ,\u001b[38;5;241m2.43981134e+02\u001b[39m, \u001b[38;5;241m1.12512536e+00\u001b[39m ,\u001b[38;5;241m1.84848683e-01\u001b[39m])\u001b[38;5;241m.\u001b[39mto(\u001b[43mdevice\u001b[49m)\n\u001b[1;32m      6\u001b[0m condition_std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.19021432e+02\u001b[39m, \u001b[38;5;241m1.23790469e+02\u001b[39m, \u001b[38;5;241m1.13191379e+00\u001b[39m ,\u001b[38;5;241m2.54632684e-02\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "text =[300,200,0.2,0.2]\n",
    "text = torch.tensor(text, dtype=torch.float32)  # 确保数据类型一致\n",
    "\n",
    "# 定义条件均值和标准差\n",
    "condition_mean = torch.tensor([3.84952491e+02 ,2.43981134e+02, 1.12512536e+00 ,1.84848683e-01]).to(device)\n",
    "condition_std = torch.tensor([1.19021432e+02, 1.23790469e+02, 1.13191379e+00 ,2.54632684e-02]).to(device)\n",
    "\n",
    "text = text.to(device)\n",
    "text=(text - condition_mean) / condition_std\n",
    "print(text)\n",
    "\n",
    "num_buckets = 30000\n",
    "bins = torch.linspace(-2, 2, steps=num_buckets + 1, device='cuda')\n",
    "#\n",
    "# 映射数据到桶\n",
    "indices = torch.bucketize(text, bins) - 1\n",
    "indices[indices < 0] = 0 \n",
    "print(indices)\n",
    "\n",
    "\n",
    "#[1, 77, 768]\n",
    "pos = encoder(indices)\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3473952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
